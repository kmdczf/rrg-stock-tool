import streamlit as st
import akshare as ak
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import datetime
import os
import json
import warnings
import requests
import re

warnings.filterwarnings('ignore')

# ==========================================
# 1. äº‘ç«¯/æœ¬åœ° ç¯å¢ƒé€‚é… (é˜²å´©æºƒå•çº¿ç‰ˆ)
# ==========================================
os.environ['NO_PROXY'] = '*'

st.set_page_config(layout="wide", page_title="å…¨çƒ RRG (V62 æè‡´å®šå‹ç‰ˆ)")
st.markdown("""
<style>
    .stApp { background-color: #0E1117; }
    .stDeployButton, [data-testid="stToolbar"], footer {display:none;}
    [data-testid="stSidebar"] { min-width: 380px; }
    h1 { color: #00CC96; text-shadow: 2px 2px 4px #000000; }
    div.stButton > button { width: 100%; border-radius: 5px; }
    button[title="View fullscreen"] { display: none !important; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸš€ å…¨çƒ RRG æé€Ÿåˆ†æç³»ç»Ÿ (V62 å®Œç¾é—­ç¯ç‰ˆ)")

# ==========================================
# 2. æ ¸å¿ƒæœ¬åœ°æ•°æ®åº“ä¸ 31 å¤§ ETF å…µå™¨åº“
# ==========================================
DATA_DIR = "rrg_data_warehouse"
if not os.path.exists(DATA_DIR): os.makedirs(DATA_DIR)

# æ»¡è¡€ 31 å¤§æ ¸å¿ƒ ETF æ± 
A_ETF_CONFIG = {
    "sh515220": "ç…¤ç‚­ETF", "sh515210": "é’¢é“ETF", "sh512400": "æœ‰è‰²ETF",
    "sh561360": "çŸ³æ²¹ETF", "sh561560": "ç”µåŠ›ETF", "sh516020": "åŒ–å·¥ETF",
    "sh512800": "é“¶è¡ŒETF", "sh512880": "è¯åˆ¸ETF", "sh515050": "ä¿é™©ETF",
    "sh512200": "æˆ¿åœ°äº§ETF", "sh512480": "åŠå¯¼ä½“ETF", "sh515790": "å…‰ä¼ETF",
    "sh515030": "æ–°èƒ½è½¦ETF", "sz159755": "ç”µæ± ETF", "sh512690": "é…’ETF",
    "sh512010": "åŒ»è¯ETF", "sh512170": "åŒ»ç–—ETF", "sh561120": "å®¶ç”µETF",
    "sh516770": "æ¸¸æˆETF", "sh512980": "ä¼ åª’ETF", "sz159865": "å…»æ®–ETF",
    "sh515880": "é€šä¿¡ETF", "sz159998": "è®¡ç®—æœºETF", "sh512660": "å†›å·¥ETF",
    "sh516530": "ç‰©æµETF", "sh562510": "æ—…æ¸¸ETF", "sh512580": "ç¯ä¿ETF",
    "sh512530": "å»ºæETF", "sh516100": "åŸºå»ºETF", "sz159886": "æœºæ¢°ETF",
    "sh510150": "æ¶ˆè´¹ETF"
}

# ğŸŒŸ V62 æ ¸å¿ƒé—­ç¯ï¼šå°†æ–°æµªç»†åˆ†è¡Œä¸šåå‘æ˜ å°„åˆ° 31 å¤§ ETF
ETF_KEYWORD_MAP = {
    "ç…¤ç‚­": "sh515220", "é’¢é“": "sh515210", "æœ‰è‰²": "sh512400", "é‡‘å±": "sh512400",
    "çŸ³æ²¹": "sh561360", "ç”µåŠ›": "sh561560", "å‘ç”µ": "sh515790", "åŒ–å·¥": "sh516020", 
    "åŒ–çº¤": "sh516020", "å¡‘æ–™": "sh516020", "æ©¡èƒ¶": "sh516020",
    "é“¶è¡Œ": "sh512800", "é‡‘è": "sh512800", "è¯åˆ¸": "sh512880", "ä¿é™©": "sh515050", 
    "æˆ¿åœ°": "sh512200", "å›­åŒº": "sh512200", 
    "åŠå¯¼": "sh512480", "å…ƒå™¨ä»¶": "sh512480", "å…‰ä¼": "sh515790", 
    "æ±½è½¦": "sh515030", "ç”µæ± ": "sz159755", "é…¿é…’": "sh512690", "é…’": "sh512690", 
    "åŒ»è¯": "sh512010", "åˆ¶è¯": "sh512010", "ç”Ÿç‰©": "sh512010", "åŒ»ç–—": "sh512170", 
    "å®¶ç”µ": "sh561120", "ç”µå™¨": "sh561120", "æ¸¸æˆ": "sh516770", "ä¼ åª’": "sh512980",
    "å¨±ä¹": "sh516770", "å†œç‰§": "sz159865", "å…»æ®–": "sz159865", "å†œä¸š": "sz159865",
    "é€šä¿¡": "sh515880", "è®¡ç®—": "sz159998", "è½¯ä»¶": "sz159998", "äº’è”ç½‘": "sz159998",
    "å†›å·¥": "sh512660", "èˆ¹èˆ¶": "sh512660", "èˆªå¤©": "sh512660", "é£æœº": "sh512660",
    # ç»†åˆ†æ¿å—å…œåº•
    "äº¤è¿": "sh516530", "äº¤é€š": "sh516530", "ç‰©æµ": "sh516530", "å…¬è·¯": "sh516530", 
    "æ¡¥æ¢": "sh516530", "æœºåœº": "sh516530", "æ¸¯å£": "sh516530", "èˆªç©º": "sh516530",
    "æ—…æ¸¸": "sh562510", "é…’åº—": "sh562510", "é¤é¥®": "sh562510",
    "ç¯ä¿": "sh512580", "ä¾›æ°´": "sh512580", "æ°´åŠ¡": "sh512580", "ä¾›æ°”": "sh561560",
    "å»ºæ": "sh512530", "æ°´æ³¥": "sh512530", "ç»ç’ƒ": "sh512530",
    "å»ºç­‘": "sh516100", "å·¥ç¨‹": "sh516100", "æœºæ¢°": "sz159886", "æœºåºŠ": "sz159886", 
    "ä»ªå™¨": "sz159886", "æ¶ˆè´¹": "sh510150", "ç™¾è´§": "sh510150", "å•†è´¸": "sh510150", 
    "å•†ä¸š": "sh510150", "çººç»‡": "sh510150", "æœè£…": "sh510150", "è½»å·¥": "sh510150", 
    "é€ çº¸": "sh510150", "å®¶å…·": "sh510150", "åŒ…è£…": "sh510150"
}

ETF_TO_KEYWORDS = {}
for kw, etf in ETF_KEYWORD_MAP.items():
    ETF_TO_KEYWORDS.setdefault(etf, []).append(kw)

# æ»¡è¡€å¤åŸï¼šç¾è‚¡ 12 å¤§æ¿å— 100% æ‰¾å›
US_SECTOR_CONFIG = {
    "ç§‘æŠ€ (XLK)": {"etf": "XLK", "stocks": {"AAPL":"è‹¹æœ", "MSFT":"å¾®è½¯", "NVDA":"è‹±ä¼Ÿè¾¾", "AVGO":"åšé€š", "ADBE":"Adobe", "CRM":"èµ›å¯Œæ—¶", "AMD":"AMD", "ACN":"åŸƒæ£®å“²", "CSCO":"æ€ç§‘", "INTC":"è‹±ç‰¹å°”"}},
    "åŒ»ç–—å¥åº· (XLV)": {"etf": "XLV", "stocks": {"LLY":"ç¤¼æ¥", "UNH":"è”åˆå¥åº·", "JNJ":"å¼ºç”Ÿ", "MRK":"é»˜æ²™ä¸œ", "ABBV":"è‰¾ä¼¯ç»´", "TMO":"èµ›é»˜é£", "ABT":"é›…åŸ¹", "PFE":"è¾‰ç‘", "DHR":"ä¸¹çº³èµ«", "AMGN":"å®‰è¿›"}},
    "é‡‘è (XLF)": {"etf": "XLF", "stocks": {"BRK-B":"ä¼¯å…‹å¸Œå°”", "JPM":"æ‘©æ ¹å¤§é€š", "V":"Visa", "MA":"ä¸‡äº‹è¾¾", "BAC":"ç¾å›½é“¶è¡Œ", "WFC":"å¯Œå›½é“¶è¡Œ", "MS":"æ‘©æ ¹å£«ä¸¹åˆ©", "GS":"é«˜ç››", "C":"èŠ±æ——", "BLK":"è´è±å¾·"}},
    "éå¿…é€‰æ¶ˆè´¹ (XLY)": {"etf": "XLY", "stocks": {"AMZN":"äºšé©¬é€Š", "TSLA":"ç‰¹æ–¯æ‹‰", "HD":"å®¶å¾—å®", "MCD":"éº¦å½“åŠ³", "NKE":"è€å…‹", "SBUX":"æ˜Ÿå·´å…‹", "LOW":"åŠ³æ°", "BKNG":"Booking", "TJX":"TJXå…¬å¸", "TGT":"å¡”å‰ç‰¹"}},
    "å·¥ä¸š (XLI)": {"etf": "XLI", "stocks": {"GE":"é€šç”¨ç”µæ°”", "CAT":"å¡ç‰¹å½¼å‹’", "RTX":"é›·ç¥", "BA":"æ³¢éŸ³", "UNP":"è”åˆå¤ªå¹³æ´‹", "HON":"éœå°¼éŸ¦å°”", "UPS":"UPS", "LMT":"æ´›é©¬", "DE":"çº¦ç¿°è¿ªå°”", "MMM":"3M"}},
    "æ—¥å¸¸æ¶ˆè´¹ (XLP)": {"etf": "XLP", "stocks": {"PG":"å®æ´", "COST":"å¥½å¸‚å¤š", "WMT":"æ²ƒå°”ç›", "PEP":"ç™¾äº‹", "KO":"å¯å£å¯ä¹", "PM":"è²åˆ©æ™®è«é‡Œæ–¯", "MO":"å¥¥é©°äºš", "EL":"é›…è¯—å…°é»›", "CL":"é«˜éœ²æ´", "KMB":"é‡‘ä½°åˆ©"}},
    "èƒ½æº (XLE)": {"etf": "XLE", "stocks": {"XOM":"åŸƒå…‹æ£®ç¾å­š", "CVX":"é›ªä½›é¾™", "COP":"åº·è²", "SLB":"æ–¯ä¼¦è´è°¢", "EOG":"EOGèƒ½æº", "MPC":"é©¬æ‹‰æ¾åŸæ²¹", "PXD":"å…ˆé”‹è‡ªç„¶", "VLO":"ç“¦è±ç½—èƒ½æº", "PSX":"è²åˆ©æ™®æ–¯66", "OXY":"è¥¿æ–¹çŸ³æ²¹"}},
    "å…¬ç”¨äº‹ä¸š (XLU)": {"etf": "XLU", "stocks": {"NEE":"æ–°çºªå…ƒèƒ½æº", "SO":"å—æ–¹å…¬å¸", "DUK":"æœå…‹èƒ½æº", "SRE":"æ¡‘æ™®æ‹‰èƒ½æº", "AEP":"ç¾å›½ç”µåŠ›", "D":"é“æ˜å°¼èµ„æº", "PCG":"å¤ªå¹³æ´‹ç‡ƒæ°”", "EXC":"è‰¾æ–¯èƒ½", "XEL":"æ–°ä¸–çºªèƒ½æº", "ED":"è”åˆçˆ±è¿ªç”Ÿ"}},
    "æˆ¿åœ°äº§ (XLRE)": {"etf": "XLRE", "stocks": {"PLD":"æ™®æ´›æ–¯", "AMT":"ç¾å›½ç”µå¡”", "EQIX":"æ˜“æ˜†å°¼å…‹æ–¯", "CCI":"å† åŸå›½é™…", "PSA":"å¤§ä¼—ä»“å‚¨", "O":"RealtyIncome", "SPG":"è¥¿è’™åœ°äº§", "WELL":"Welltower", "DLR":"æ•°å­—æˆ¿åœ°äº§", "CSGP":"CoStar"}},
    "ææ–™ (XLB)": {"etf": "XLB", "stocks": {"LIN":"æ—å¾·", "SHW":"å®£ä¼Ÿ", "FCX":"è‡ªç”±æ¸¯", "ECL":"è‰ºåº·", "APD":"ç©ºæ°”åŒ–å·¥", "NEM":"çº½è’™ç‰¹", "DOW":"é™¶æ°", "NUE":"çº½æŸ¯", "CTVA":"ç§‘è¿ªå", "VMC":"ç«ç¥ææ–™"}},
    "é€šä¿¡æœåŠ¡ (XLC)": {"etf": "XLC", "stocks": {"GOOGL":"è°·æ­ŒA", "META":"Meta", "NFLX":"å¥ˆé£", "TMUS":"T-Mobile", "DIS":"è¿ªå£«å°¼", "VZ":"å¨ç‘æ£®", "CMCSA":"åº·å¡æ–¯ç‰¹", "T":"AT&T", "CHTR":"ç‰¹è®¸é€šè®¯", "EA":"EAæ¸¸æˆ"}},
    "æœ¬åœŸåŸºå»º (AIRR)": {"etf": "AIRR", "stocks": {"STRL":"Sterling", "MTZ":"MasTec", "EME":"EMCOR", "FIX":"Comfort", "PRIM":"Primoris", "DY":"Dycom", "PWR":"Quanta", "URI":"UnitedRent", "PAVE":"PAVEåŸºå»º", "XHB":"å»ºç­‘å•†"}}
}

# ==========================================
# 3. æé€Ÿæœ¬åœ°åŒ–æŠ“å–å¼•æ“
# ==========================================
@st.cache_data(ttl=86400)
def get_sina_board_mapping():
    local_file = os.path.join(DATA_DIR, "sina_boards.json")
    try:
        df = ak.stock_sector_spot(indicator="æ–°æµªè¡Œä¸š")
        if not df.empty:
            mapping = dict(zip(df['æ¿å—'], df['label']))
            with open(local_file, 'w', encoding='utf-8') as f: json.dump(mapping, f, ensure_ascii=False)
            return mapping
    except: pass
    if os.path.exists(local_file):
        with open(local_file, 'r', encoding='utf-8') as f: return json.load(f)
    return {"åŠå¯¼ä½“": "new_bdt", "äº¤é€šè¿è¾“": "new_jtys"}

@st.cache_data(ttl=3600)
def get_constituents_safe(sina_label, limit):
    local_file = os.path.join(DATA_DIR, f"cons_{sina_label}.json")
    try:
        url = f"http://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/Market_Center.getHQNodeData?page=1&num={limit}&sort=amount&asc=0&node={sina_label}"
        resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=6)
        text = re.sub(r'([{,])([a-zA-Z0-9_]+):', r'\1"\2":', resp.text)
        data = json.loads(text)
        df = pd.DataFrame(data)
        
        if not df.empty:
            res = {}
            for _, row in df.iterrows():
                code = str(row['symbol']).strip() 
                name = str(row['name']).strip()
                clean_code = code.replace('sh', '').replace('sz', '')
                fc = f"sh{clean_code}" if clean_code.startswith(('6','9','5')) else f"sz{clean_code}"
                res[fc] = name
            with open(local_file, 'w', encoding='utf-8') as f: json.dump(res, f, ensure_ascii=False)
            return res
    except: pass
    if os.path.exists(local_file):
        with open(local_file, 'r', encoding='utf-8') as f: return json.load(f)
    return {}

# ==========================================
# 4. å•çº¿å®‰å…¨ K çº¿ä¸‹è½½ä¸æ·±åº¦ç¼“å­˜
# ==========================================
def fetch_kline_safe(code, start_date, is_us, p_code):
    if is_us:
        try:
            if p_code in ['1h', '60m']: start = (datetime.datetime.now() - datetime.timedelta(days=700)).strftime("%Y-%m-%d")
            elif p_code in ['15m']: start = (datetime.datetime.now() - datetime.timedelta(days=50)).strftime("%Y-%m-%d")
            else: start = "2023-01-01"
            df = yf.Ticker(code).history(interval=p_code, start=start)
            if not df.empty:
                df = df.reset_index()
                df['date'] = pd.to_datetime(df[df.columns[0]]).dt.tz_localize(None)
                return df.set_index('date')[['Close']].rename(columns={'Close':'close'})
        except: return None
    else:
        if any(x in code for x in ['51','15','56']):
            try:
                df = ak.fund_etf_hist_sina(symbol=code)
                if not df.empty:
                    df['date'] = pd.to_datetime(df['date'])
                    return df.set_index('date')[['close']]
            except: pass
        try:
            url = f"http://money.finance.sina.com.cn/quotes_service/api/json_v2.php/CN_MarketData.getKLineData?symbol={code}&scale=240&ma=no&datalen=800"
            resp = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=6)
            text = re.sub(r'([{,])([a-zA-Z0-9_]+):', r'\1"\2":', resp.text)
            df = pd.DataFrame(json.loads(text))
            if not df.empty:
                df['date'] = pd.to_datetime(df['day'])
                df = df[df['date'] >= pd.to_datetime(start_date)]
                return df.set_index('date')[['close']].astype(float)
        except: pass
        try:
            yf_code = code.replace("sh", "") + ".SS" if "sh" in code else code.replace("sz", "") + ".SZ"
            df = yf.Ticker(yf_code).history(start=start_date)
            if not df.empty:
                df = df.reset_index()
                df['date'] = pd.to_datetime(df[df.columns[0]]).dt.tz_localize(None)
                return df.set_index('date')[['Close']].rename(columns={'Close':'close'})
        except: pass
    return None

def get_data_smart(code, start_date, force_refresh, is_us, p_code):
    file_path = os.path.join(DATA_DIR, f"{code}_{p_code}.csv" if is_us else f"{code}.csv")
    if os.path.exists(file_path) and not force_refresh:
        mtime = datetime.date.fromtimestamp(os.path.getmtime(file_path))
        if mtime == datetime.date.today():
            try: return pd.read_csv(file_path, index_col=0, parse_dates=True)['close']
            except: pass
            
    df_new = fetch_kline_safe(code, start_date, is_us, p_code)
    if df_new is not None and not df_new.empty:
        try: df_new.to_csv(file_path) 
        except: pass
        return df_new['close']
        
    if os.path.exists(file_path): 
        try: return pd.read_csv(file_path, index_col=0, parse_dates=True)['close']
        except: pass
    return None

# ==========================================
# ğŸŒŸ æ ¸å¿ƒé»‘ç§‘æŠ€ï¼šè‡ªå»ºç­‰æƒæ¿å—èµ°åŠ¿å¼•æ“
# ==========================================
@st.cache_data(ttl=3600)
def load_data_stable(pool, board_mapping, bench, start, _force, is_us, p_code):
    data, fails = {}, []
    status = st.empty(); bar = st.progress(0)
    
    status.text(f"è¯»å–åŸºå‡†: {bench}...")
    b_s = get_data_smart(bench, start, _force, is_us, p_code)
    if b_s is None: return None, ["åŸºå‡†"]
    data['__BENCH__'] = b_s
    full_idx = b_s.index
    
    # ç¬¬ä¸€æ­¥ï¼šä¸‹è½½å¹¶æå–æ‰€æœ‰æ­£è‚¡ (é¿å¼€ä»¥ BK_ å¼€å¤´çš„ä¼ªä»£ç )
    normal_items = {k: v for k, v in pool.items() if not str(k).startswith("BK_")}
    bk_items = {k: v for k, v in pool.items() if str(k).startswith("BK_")}
    
    total = len(normal_items)
    for i, (k, v) in enumerate(normal_items.items()):
        status.text(f"å®‰å…¨åŒæ­¥æ•°æ® (å›ºåŒ–åæ¬¡æ—¥ç§’å¼€) ({i+1}/{total}): {v}...")
        bar.progress((i+1)/total if total > 0 else 1.0)
        s = get_data_smart(k, start, _force, is_us, p_code)
        if s is not None:
            s = s[~s.index.duplicated(keep='last')]
            data[v] = s.reindex(full_idx).ffill()
        else:
            fails.append(v)
            
    # ç¬¬äºŒæ­¥ï¼šæœ¬åœ°åˆæˆå„ç»†åˆ†æ¿å—çš„ç­‰æƒèµ°åŠ¿ (å®Œå…¨ä¸è”ç½‘ï¼)
    if bk_items:
        status.text("æ­£åœ¨æœ¬åœ°åˆæˆç­‰æƒæ¿å—èµ°åŠ¿...")
        for k, v in bk_items.items():
            board_name = k[3:] # å‰¥ç¦» "BK_"
            codes = board_mapping.get(board_name, [])
            valid_series = []
            
            for c in codes:
                name = pool.get(c)
                if name and name in data:
                    s = data[name]
                    first_valid = s.first_valid_index()
                    # å½’ä¸€åŒ–ä¸º 100 è¿›è¡Œç­‰æƒè®¡ç®—
                    if first_valid is not None and s.loc[first_valid] != 0:
                        norm_s = s / s.loc[first_valid] * 100
                        valid_series.append(norm_s)
            
            if valid_series:
                df_board = pd.concat(valid_series, axis=1)
                data[v] = df_board.mean(axis=1) # åˆæˆå‡ºæ¿å—çš„èµ°åŠ¿çº¿ï¼
            else:
                fails.append(v)

    status.empty(); bar.empty()
    return pd.DataFrame(data), fails

# ==========================================
# 5. ä¾§è¾¹æ äº¤äº’ (æ— ç¼è¿é€šåº•å±‚ç»†åˆ†)
# ==========================================
board_mapping = {} # ç”¨äºå‘å¼•æ“ä¼ é€’â€œå“ªä¸ªæ¿å—åŒ…å«å“ªäº›è‚¡ç¥¨â€çš„å­—å…¸

with st.sidebar:
    st.header("1ï¸âƒ£ è§†è§’é€‰æ‹©")
    market = st.selectbox("ğŸŒ å¸‚åœºç¯å¢ƒ", ["ğŸ‡¨ğŸ‡³ Aè‚¡ (æ ¸å¿ƒETFé€è§†åº•å±‚)", "ğŸ‡ºğŸ‡¸ ç¾è‚¡ (ç½‘ç»œç›´è¿)"], index=0)
    is_us = "ç¾è‚¡" in market
    level = st.radio("æ¨¡å¼", ["Level 1: æ ¸å¿ƒ ETF è½®åŠ¨", "Level 2: å®è§‚èµ›é“é€è§†åº•å±‚ç»†åˆ†"])
    
    if is_us: 
        st.info("ğŸ’¡ æç¤º: ç¾è‚¡æ•°æ®é¦–æ¬¡åŠ è½½éœ€æ’é˜Ÿï¼Œå·²å¼€å¯æœ¬åœ°ç¼“å­˜æœºåˆ¶ï¼")
        BENCHMARK_DICT = {"æ ‡æ™®500 (SPY)": "SPY", "çº³æ–¯è¾¾å…‹ (QQQ)": "QQQ", "ç½—ç´ 2000 (IWM)": "IWM"}
    else: 
        st.info("ğŸ›¡ï¸ è‡ªåŠ¨é˜²å°é”: é‡‡ç”¨å•çº¿å®‰å…¨è¿æ¥+æœ¬åœ°è‡ªå»ºæŒ‡æ•°åˆæˆã€‚")
        BENCHMARK_DICT = {"æ²ªæ·±300 (æœºæ„)": "sh510300", "çº¢åˆ©ETF (é¿é™©)": "sh510880", "ä¸­è¯2000 (æ¸¸èµ„)": "sh563300"}
        
    bench_choice = st.selectbox("ğŸ¯ å‚ç…§ç³»åŸºå‡†", list(BENCHMARK_DICT.keys()) + ["è‡ªå®šä¹‰"])
    if bench_choice == "è‡ªå®šä¹‰": benchmark_code = st.text_input("ä»£ç ", "SPY" if is_us else "sh510300").strip().upper()
    else: benchmark_code = BENCHMARK_DICT[bench_choice]
        
    st.caption(f"å½“å‰ç”Ÿæ•ˆåŸºå‡†: {benchmark_code}")
    current_pool = {}
    
    if is_us:
        if "Level 1" in level:
            current_pool = {v['etf']: k for k, v in US_SECTOR_CONFIG.items()}
            if benchmark_code in current_pool: del current_pool[benchmark_code]
        else:
            sector_key = st.selectbox("é€‰æ‹©ç¾è‚¡æ¿å—", list(US_SECTOR_CONFIG.keys()))
            benchmark_code = US_SECTOR_CONFIG[sector_key]['etf'] 
            st.caption(f"è‡ªåŠ¨åˆ‡æ¢åŸºå‡†: {benchmark_code}")
            current_pool = US_SECTOR_CONFIG[sector_key]['stocks']
    else:
        if "Level 1" in level:
            current_pool = A_ETF_CONFIG.copy()
            if benchmark_code in current_pool: del current_pool[benchmark_code]
        else:
            # ğŸŒŸ V62 ç»ˆæé—­ç¯ï¼šé€‰èµ›é“ -> æ‰¾ç»†åˆ† -> åˆ ä¸»ETF -> åˆæˆç»†åˆ†èµ°åŠ¿
            etf_options = {f"{name} ({code})": code for code, name in A_ETF_CONFIG.items()}
            selected_label = st.selectbox("é€‰æ‹©å®è§‚èµ›é“ (è‡ªåŠ¨é€è§†åº•å±‚ç›¸å…³ç»†åˆ†è¡Œä¸š)", list(etf_options.keys()))
            selected_etf_code = etf_options[selected_label]
            
            # è®¾ç½®è¯¥å®è§‚ ETF ä¸ºè½®åŠ¨ä¸­å¿ƒç³»
            benchmark_code = selected_etf_code
            st.caption(f"ğŸ¯ ä¸­å¿ƒåŸºå‡†å·²é”å®šä¸º: {selected_label}")
            
            keywords = ETF_TO_KEYWORDS.get(selected_etf_code, [A_ETF_CONFIG[selected_etf_code].replace("ETF", "")])
            sina_mapping = get_sina_board_mapping()
            matched_boards = [board for board in sina_mapping.keys() if any(kw in board for kw in keywords)]
            
            st.caption(f"ğŸ”— å·²ç©¿é€æŠ“å–æ–°æµªåº•å±‚ç»†åˆ†: {', '.join(matched_boards) if matched_boards else 'å®½åŸºç»¼åˆæå–'}")
            
            top_n = st.slider("å„ç»†åˆ†æ¿å—æˆªå–å‰ N åªé¾™å¤´", 5, 50, 15)
            
            with st.spinner("æ­£åœ¨æå–å¹¶å‡†å¤‡æœ¬åœ°åˆæˆç®—æ³•..."):
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ˜ç¡®åˆ é™¤äº†ä¸» ETF çš„èµ°åŠ¿ï¼Œè½¬è€Œä¸ºæ¯ä¸ªç»†åˆ†æ¿å—ç”Ÿæˆä¸€æ¡è¶‹åŠ¿çº¿
                for board in matched_boards:
                    label = sina_mapping[board]
                    board_stocks = get_constituents_safe(label, top_n)
                    if board_stocks:
                        # åŠ å…¥åº•å±‚é¾™å¤´ä¸ªè‚¡
                        current_pool.update(board_stocks)
                        # è®°å½•æ­¤æ¿å—åŒ…å«å“ªäº›ä¸ªè‚¡ä»£ç ï¼Œä¾›å¼•æ“æœ¬åœ°åˆæˆæŒ‡æ•°
                        board_mapping[board] = list(board_stocks.keys())
                        # ä¸‹è¾¾åˆæˆæŒ‡ä»¤ï¼šåŠ ä¸Šâ€œäº¤è¿ã€å…¬è·¯â€ç­‰æ¿å—è‡ªèº«çš„èµ°åŠ¿
                        current_pool[f"BK_{board}"] = f"ğŸŒŸ {board} (ç­‰æƒèµ°åŠ¿)"
                
                if not current_pool:
                    st.error("ğŸš¨ æå–å¤±è´¥æˆ–æ— å¯¹åº”ç»†åˆ†ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
            
    extra = st.text_input("â• æ…å±€è€… (ä»£ç ,åç§°)", "")
    if extra:
        p = extra.split(',')
        if is_us: current_pool[p[0].strip().upper()] = p[1].strip() if len(p)>1 else p[0].strip()
        else: current_pool[p[0].strip()] = p[1].strip() if len(p)>1 else p[0].strip()

    st.divider()
    st.header("2ï¸âƒ£ å‚æ•° (å¼•æ“ä¸å°¾æ°”)")
    if is_us:
        period_name = st.radio("æ—¶é—´å‘¨æœŸ", ["æ—¥çº¿ (1d)", "å‘¨çº¿ (1wk)", "1å°æ—¶ (1h)", "15åˆ†é’Ÿ (15m)"], index=0)
        period_code = period_name.split('(')[1].replace(')', '')
    else:
        period = st.radio("æ—¶é—´å‘¨æœŸ", ["æ—¥çº¿", "å‘¨çº¿"], index=0)
        period_code = 'W-FRI' if "å‘¨" in period else 'D'
        
    col1, col2 = st.columns(2)
    with col1: window = st.number_input("RSçª—å£", 5, 60, 14)
    with col2: tail_len = st.number_input("æ‹–å°¾é•¿åº¦", 1, 30, 8)

    st.divider()
    force_update = st.button("ğŸ”„ å¼ºåˆ¶ç©¿é€åˆ·æ–°ä»Šæ—¥æ•°æ®")

# ==========================================
# 6. è®¡ç®—é€»è¾‘ (è¿˜åŸé»„é‡‘å¹³æ»‘ç®—æ³•)
# ==========================================
def calculate_rrg(df, period, window, tail):
    if period in ['D', '1d', '1h', '15m']: df_res = df
    else: df_res = df.resample('W-FRI').last()
    
    df_res = df_res.dropna(how='all')
    if len(df_res) < window + 5: return pd.DataFrame(), [], "æ•°æ®é•¿åº¦ä¸è¶³"

    bench = df_res['__BENCH__']
    worm_data = []
    dates = df_res.index[window+10:]
    if len(dates) > 52: dates = dates[-52:]
    
    time_format = '%Y-%m-%d %H:%M' if period in ['1h', '15m'] else '%Y-%m-%d'
    str_dates = [d.strftime(time_format) for d in dates]
    
    for col in df_res.columns:
        if col == '__BENCH__': continue
        series = df_res[col]
        if series.notna().sum() < window + 5: continue
        
        rs = series / bench
        
        rs_smooth = rs.ewm(span=5, adjust=False).mean()
        rs_mean = rs_smooth.rolling(window).mean()
        rs_std = rs_smooth.rolling(window).std()
        
        ratio = 100 + ((rs_smooth - rs_mean) / rs_std) * 1.5
        mom = 100 + ((ratio - ratio.rolling(window).mean()) / ratio.rolling(window).std()) * 1.5
        
        ratio = ratio.ewm(span=3, adjust=False).mean()
        mom = mom.ewm(span=3, adjust=False).mean()
        
        temp = pd.DataFrame({'R': ratio, 'M': mom, 'P': series}, index=df_res.index)
        
        for d_str, dt_obj in zip(str_dates, dates):
            try:
                hist = temp.loc[:dt_obj].tail(tail + 1)
                if len(hist) > 0 and not np.isnan(hist.iloc[-1]['R']):
                    worm_data.append({'Frame': d_str, 'Name': col, 'X': hist['R'].tolist(), 'Y': hist['M'].tolist(), 'P': hist['P'].iloc[-1]})
            except: pass
            
    return pd.DataFrame(worm_data), str_dates, "OK"

# ==========================================
# 7. ä¸»ç¨‹åºæ¸²æŸ“
# ==========================================
if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    start_date = "2021-01-01"
    
    # å°† board_mapping ä¼ å…¥ï¼Œä¾›åº•å±‚åˆæˆæŒ‡æ•°ä½¿ç”¨
    raw_df, fails = load_data_stable(current_pool, board_mapping, benchmark_code, start_date, force_update, is_us, period_code)
    
    if fails: st.toast(f"å·²è‡ªåŠ¨è¿‡æ»¤ {len(fails)} åªåœç‰Œæˆ–æ— æ•°æ®èµ„äº§", icon="âœ…")
    
    if raw_df is None:
        st.error("âŒ åŸºå‡†æ•°æ®è·å–å¤±è´¥ï¼")
    elif not current_pool:
        st.error("âŒ è‚¡ç¥¨æ± ä¸ºç©ºï¼")
    else:
        worms, dates, msg = calculate_rrg(raw_df, period_code, window, tail_len)
        
        if worms.empty:
            st.error(f"âŒ é”™è¯¯: {msg}")
        else:
            fig = go.Figure()
            def add_q(x0, x1, y0, y1, c):
                fig.add_shape(type="rect", x0=x0, x1=x1, y0=y0, y1=y1, fillcolor=c, opacity=0.08, line_width=0, layer="below")
            add_q(90,100,100,110,"cyan"); add_q(100,110,100,110,"green")
            add_q(90,100,90,100,"red"); add_q(100,110,90,100,"yellow")
            fig.add_hline(y=100, line_color="#444"); fig.add_vline(x=100, line_color="#444")
            
            # --- ğŸŒŸ å®Œç¾å±…ä¸­çš„è‰ºæœ¯ Logo ---
            logo_x, logo_y = 0.5, 0.96
            fig.add_annotation(
                text="â—¯", x=logo_x, y=logo_y, xref="paper", yref="paper",
                xanchor="center", yanchor="middle",
                showarrow=False, font=dict(size=120, color="rgba(0, 204, 150, 0.15)")
            )
            fig.add_annotation(
                text="<span style='font-family: \"Arial Black\", Impact, sans-serif; font-style: italic; letter-spacing: 2px;'>ZF</span>", 
                x=logo_x, y=logo_y, xref="paper", yref="paper",
                xanchor="center", yanchor="middle",
                showarrow=False, font=dict(size=45, color="rgba(0, 204, 150, 0.25)")
            )

            fig.add_annotation(x=105,y=105,text="é¢†å…ˆ",showarrow=False,font=dict(color="green",size=16))
            fig.add_annotation(x=95,y=105,text="æ”¹å–„",showarrow=False,font=dict(color="cyan",size=16))
            fig.add_annotation(x=95,y=95,text="è½å",showarrow=False,font=dict(color="red",size=16))
            fig.add_annotation(x=105,y=95,text="è½¬å¼±",showarrow=False,font=dict(color="yellow",size=16))

            last_d = dates[-1]
            init = worms[worms['Frame'] == last_d]
            
            for name in worms['Name'].unique():
                row = init[init['Name'] == name]
                x, y = (row.iloc[0]['X'], row.iloc[0]['Y']) if not row.empty else ([],[])
                
                # ç‰¹æ®Šé«˜äº®å¤„ç†ï¼šå¯¹äºè‡ªå»ºçš„ç»†åˆ†æ¿å—èµ°åŠ¿ï¼ŒåŠ ç²—åŠ äº®
                is_sector_line = "ğŸŒŸ" in name
                line_width = 4 if is_sector_line else 2
                marker_size = [6]*(len(x)-1)+[18] if is_sector_line else [4]*(len(x)-1)+[14]
                
                fig.add_trace(go.Scatter(
                    x=x, y=y, mode='lines+markers', name=name, 
                    marker=dict(size=marker_size, line=dict(width=1,color='white')),
                    line=dict(width=line_width, shape='spline', smoothing=1.3)
                ))
            
            frames = []
            for d in dates:
                fd = []
                frm = worms[worms['Frame'] == d]
                for name in worms['Name'].unique():
                    r = frm[frm['Name'] == name]
                    x_fd = r.iloc[0]['X'] if not r.empty else []
                    y_fd = r.iloc[0]['Y'] if not r.empty else []
                    fd.append(go.Scatter(x=x_fd, y=y_fd))
                frames.append(go.Frame(data=fd, name=d))
            fig.frames = frames
            
            btn_play = dict(label="â–¶ï¸ æ’­æ”¾", method="animate", args=[None, dict(frame=dict(duration=150, redraw=True), fromcurrent=True)])
            btn_pause = dict(label="â¸ï¸ æš‚åœ", method="animate", args=[[None], dict(mode="immediate")])
            menu_dict = dict(type="buttons", direction="left", buttons=[btn_play, btn_pause], pad={"r": 10, "t": 10}, showactive=True, x=0.0, xanchor="left", y=1.15, yanchor="bottom")
            
            fig.update_layout(
                title=f"RRG è½®åŠ¨å›¾ ({last_d})", template="plotly_dark", 
                height=880, 
                margin=dict(t=100, b=180),
                xaxis=dict(range=[94,106], title="RS-Ratio (è¶‹åŠ¿)"), 
                yaxis=dict(range=[94,106], title="RS-Mom (åŠ¨èƒ½)"),
                legend=dict(orientation="h", yanchor="top", y=-0.28, xanchor="center", x=0.5),
                updatemenus=[menu_dict], sliders=[dict(steps=[dict(method='animate', args=[[d], dict(mode='immediate')], label=d) for d in dates])]
            )
            
            st.plotly_chart(fig, use_container_width=True, config={'displaylogo': False, 'scrollZoom': True, 'modeBarButtonsToRemove': ['autoScale2d']})
            
            st.divider()
            st.subheader("ğŸš¨ é›·è¾¾ç›‘æ§åŒºï¼šä¸»å‡æµªä¸åº•éƒ¨æŠ¢ç­¹å‘ç°å™¨")
            burst_list = []
            for _, row in init.iterrows():
                x_t, y_t = row['X'], row['Y']
                if len(x_t) >= 2:
                    dx, dy = x_t[-1] - x_t[-2], y_t[-1] - y_t[-2]
                    cx, cy = x_t[-1], y_t[-1]
                    sig = None
                    if cx > 100 and cy > 100 and dx > 0.1 and dy > 0.1: sig = "ğŸ”¥ å¼ºè€…æ’å¼º (å³ä¾§ä¸»å‡æµª)"
                    elif dy > 0.8 and abs(dx) < 0.5 and cx < 101: sig = "ğŸš€ åº•éƒ¨æŠ¢ç­¹ (å‚ç›´çˆ†å‘)"
                    if sig: burst_list.append({'æ ‡çš„': row['Name'], 'ä¿¡å·': sig, 'æœ€æ–°ä»·': row['P'], 'åŠ¨èƒ½Î”Y': dy, 'è¶‹åŠ¿Î”X': dx})
            
            if burst_list:
                b_df = pd.DataFrame(burst_list).sort_values(by=['ä¿¡å·', 'åŠ¨èƒ½Î”Y'], ascending=[True, False])
                st.success(f"å‘ç° {len(b_df)} åªå¼‚åŠ¨æ ‡çš„ ğŸ‘‡")
                col_cfg = {"åŠ¨èƒ½Î”Y": st.column_config.NumberColumn(format="%+.2f"), "è¶‹åŠ¿Î”X": st.column_config.NumberColumn(format="%+.2f")}
                st.dataframe(b_df.set_index('æ ‡çš„'), use_container_width=True, column_config=col_cfg)
            else: st.info("ğŸŸ¢ å½“å‰æ‰«ææ— å¼‚åŠ¨æ ‡çš„ã€‚")